{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performace criteria for different Classification Machine Learning algorithms\n",
    "1) Support Vector Machines (Kernels - Linear, poly, rbf, sigmoid)\n",
    "2) Random Forest classifier\n",
    "3) Neural Networks Regression\n",
    "4) Logistic Regression\n",
    "5) K-Nearest Neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='ML_performance_metric.txt' mode='w' encoding='utf-8'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a .txt file to store the performance metric of the different machine learning algorithms\n",
    "open(\"ML_performance_metric.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Breast Cancer dataset using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset and pre-processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"breast_cancer.csv\")\n",
    "\n",
    "# Dropping the \"id\" column as it's not useful for prediction\n",
    "data.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "# Encoding the 'diagnosis' column ('B' -> 0, 'M' -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[\"diagnosis\"])\n",
    "y = data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis                  0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave_points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values by imputing with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model using different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649\n",
      "Precision: 0.9672\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.9516\n",
      "------------------------------\n",
      "Metrics saved to ML_performance_metric.txt\n",
      "Kernel: poly\n",
      "Accuracy: 0.9415\n",
      "Precision: 0.9818\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.9153\n",
      "------------------------------\n",
      "Metrics saved to ML_performance_metric.txt\n",
      "Kernel: rbf\n",
      "Accuracy: 0.9357\n",
      "Precision: 1.0000\n",
      "Recall: 0.8254\n",
      "F1 Score: 0.9043\n",
      "------------------------------\n",
      "Metrics saved to ML_performance_metric.txt\n",
      "Kernel: sigmoid\n",
      "Accuracy: 0.4678\n",
      "Precision: 0.1818\n",
      "Recall: 0.1270\n",
      "F1 Score: 0.1495\n",
      "------------------------------\n",
      "Metrics saved to ML_performance_metric.txt\n"
     ]
    }
   ],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "file_path = \"ML_performance_metric.txt\"\n",
    "\n",
    "for k in kernels:\n",
    "    print(f\"Kernel: {k}\")\n",
    "    \n",
    "    svm = SVC(kernel = k, random_state = 42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate PERFORMANCE METRICS\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    algorithm_name = f\"SVM: Kernel - {k}\"\n",
    "\n",
    "    with open(file_path, \"a\") as file:\n",
    "        file.write(\"-\" * 50 + \"\\n\")\n",
    "        file.write(f\"Performance Metrics for {algorithm_name} \\n\")\n",
    "        file.write(f\"Accuracy: {accuracy:.4f} \\n\")\n",
    "        file.write(f\"Precision: {precision:.4f} \\n\")\n",
    "        file.write(f\"Recall: {recall:.4f} \\n\")\n",
    "        file.write(f\"F1 Score: {f1:.4f} \\n\")\n",
    "\n",
    "    print(f\"Metrics saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of the Breast Cancer dataset using Random Forest (RF) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset & data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"breast_cancer.csv\")\n",
    "\n",
    "# Dropping the \"id\" column as it's not useful for prediction\n",
    "data.drop(columns = [\"id\"], inplace = True)\n",
    "\n",
    "# Encoding the \"diagnosis\" column ('B' -> 0, 'M' -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns = [\"diagnosis\"])\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy = \"mean\")\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9708\n",
      "Precision: 0.9833\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.9593\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the trained algorithm\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate PERFORMANCE metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to ML_performance_metric.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = \"ML_performance_metric.txt\"\n",
    "algorithm_name = f\"Random Forest classifier \\n\"\n",
    "\n",
    "with open(file_path, \"a\") as file:\n",
    "    file.write(\"-\" * 50 + \"\\n\")\n",
    "    file.write(f\"Performance Metrics for {algorithm_name} \\n\")\n",
    "    file.write(f\"Accuracy: {accuracy:.4f} \\n\")\n",
    "    file.write(f\"Precision: {precision:.4f} \\n\")\n",
    "    file.write(f\"Recall: {recall:.4f} \\n\")\n",
    "    file.write(f\"F1 Score: {f1:.4f} \\n\")\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of the Breast Cancer dataset using Neural Network Regression (Multi-Layer Perceptron [MLP] Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset and data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"breast_cancer.csv\")\n",
    "\n",
    "data.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "# Encode the 'diagnosis' column ('B' -> 0, 'M' -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[\"diagnosis\"])\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Neural Network algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649\n",
      "Precision: 0.9672\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.9516\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mlp_model.predict(X_test)\n",
    "\n",
    "# Calculate PERFORMANCE metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to ML_performance_metric.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = \"ML_performance_metric.txt\"\n",
    "algorithm_name = f\"Neural Network Regression \\n\"\n",
    "\n",
    "with open(file_path, \"a\") as file:\n",
    "    file.write(\"-\" * 50 + \"\\n\")\n",
    "    file.write(f\"Performance Metrics for {algorithm_name} \\n\")\n",
    "    file.write(f\"Accuracy: {accuracy:.4f} \\n\")\n",
    "    file.write(f\"Precision: {precision:.4f} \\n\")\n",
    "    file.write(f\"Recall: {recall:.4f} \\n\")\n",
    "    file.write(f\"F1 Score: {f1:.4f} \\n\")\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of the Breast Cancer dataset using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset and data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"breast_cancer.csv\")\n",
    "\n",
    "# Drop the 'id' column as it's not useful for prediction\n",
    "data.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "# Encode the 'diagnosis' column ('B' -> 0, 'M' -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=[\"diagnosis\"])\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825\n",
      "Precision: 0.9688\n",
      "Recall: 0.9841\n",
      "F1 Score: 0.9764\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state = 42, max_iter = 1000)\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Calculate PERFORMANCE metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to ML_performance_metric.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = \"ML_performance_metric.txt\"\n",
    "algorithm_name = f\"Logistic Regression \\n\"\n",
    "\n",
    "with open(file_path, \"a\") as file:\n",
    "    file.write(\"-\" * 50 + \"\\n\")\n",
    "    file.write(f\"Performance Metrics for {algorithm_name} \\n\")\n",
    "    file.write(f\"Accuracy: {accuracy:.4f} \\n\")\n",
    "    file.write(f\"Precision: {precision:.4f} \\n\")\n",
    "    file.write(f\"Recall: {recall:.4f} \\n\")\n",
    "    file.write(f\"F1 Score: {f1:.4f} \\n\")\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of the Breast Cancer dataset using K-Nearest Neighbours (KNN) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset and data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"breast_cancer.csv\")\n",
    "\n",
    "# Drop the 'id' column as it's not useful for prediction\n",
    "data.drop(columns = [\"id\"], inplace = True)\n",
    "\n",
    "# Encode the 'diagnosis' column ('B' -> 0, 'M' -> 1)\n",
    "label_encoder = LabelEncoder()\n",
    "data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns = [\"diagnosis\"])\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy = \"mean\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9591\n",
      "Precision: 0.9516\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.9440\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate PERFORMANCE metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to ML_performance_metric.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = \"ML_performance_metric.txt\"\n",
    "algorithm_name = f\"K-Nearest Neighbours \\n\"\n",
    "\n",
    "with open(file_path, \"a\") as file:\n",
    "    file.write(\"-\" * 50 + \"\\n\")\n",
    "    file.write(f\"Performance Metrics for {algorithm_name} \\n\")\n",
    "    file.write(f\"Accuracy: {accuracy:.4f} \\n\")\n",
    "    file.write(f\"Precision: {precision:.4f} \\n\")\n",
    "    file.write(f\"Recall: {recall:.4f} \\n\")\n",
    "    file.write(f\"F1 Score: {f1:.4f} \\n\")\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
